{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "You are given a 4x4 GridWorld where an agent starts at the top-left corner (state 0) and tries to reach the bottom-right corner (state 15). The agent can move up, down, left or right with equal probability. The rewards are -1 for each move, and the terminal state (bottom-right) has a reward 0. There are no obstacles. Your task is to:\n",
        "\n",
        "> 1) initialize V(s) to 0 for all states\n",
        "\n",
        "> 2) Iteratively apply the Bellman equation until convergence:\n",
        "image.png\n",
        "where P(s'|s, a) is the transition probability (equal for all moves)\n",
        "\n",
        "> 3) Use gamma = 1 (no discounting)\n",
        "\n",
        "> 4) Stop when maximum change in V(s) across all states is < 1e - 4\n",
        "\n",
        "\n",
        "## Pseudo Code:\n",
        "\n",
        "1) Initialize:\n",
        "\n",
        "> 1) set grid size (NxN)\n",
        "\n",
        "> 2) Define rewards for each state (-1 per move, 0 for terminal state)\n",
        "\n",
        "> 3) initialize value function V(s) = 0 for each states\n",
        "\n",
        "> 4) set discount factor (gamma) and convergence threshold (theta)\n",
        "\n",
        "2) Define possible actions: up, down, left, right.\n",
        "\n",
        "3) Repeat until value converges:\n",
        "\n",
        "> 1) track maximum changes in values\n",
        "\n",
        "> 2) create a copy of current value function V_new\n",
        "\n",
        "> 3) for each state s (excluding the terminal state):\n",
        "\n",
        ">> 1) compute new value using the Bellman Equation:\n",
        "\n",
        ">> 2) for each action, calculate:\n",
        "\n",
        ">>> 1) next state s' (handling grid boundaries)\n",
        "\n",
        ">>> 2) expected value update: sum over all possible s'\n",
        "\n",
        ">> 3) update V_new(s)\n",
        "\n",
        ">> 4) track max change (to see if converged)\n",
        "\n",
        "> 4) Set V = V_new (update value function)\n",
        "\n",
        "> 5) if threshold reached, then stop\n",
        "\n",
        "4) Print the final value function. It would look something like this:\n",
        "\n",
        "[[-59.42367735 -57.42387125 -54.2813141  -51.71012579]\n",
        "\n",
        " [-57.42387125 -54.56699476 -49.71029394 -45.13926711]\n",
        "\n",
        " [-54.2813141  -49.71029394 -40.85391609 -29.99766609]\n",
        "\n",
        " [-51.71012579 -45.13926711 -29.99766609   0.        ]]\n",
        "\n",
        "5) Upload the Jupyter notebook to Gihub and share the link. Readme must show the final output like above.\n",
        ""
      ],
      "metadata": {
        "id": "9IE3bXXZbvBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Use GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# GridWorld parameters\n",
        "grid_size = 4\n",
        "theta = 1e-4           # convergence threshold\n",
        "gamma = 1.0            # discount factor (no discounting)\n",
        "\n",
        "# Initialize value function V(s) = 0 for all states\n",
        "V = torch.zeros((grid_size, grid_size), device=device)\n",
        "\n",
        "# Create a boolean mask for terminal state (bottom-right corner)\n",
        "terminal_mask = torch.zeros((grid_size, grid_size), dtype=torch.bool, device=device)\n",
        "terminal_mask[-1, -1] = True  # terminal state at (3, 3)\n",
        "\n",
        "delta = float('inf')\n",
        "\n",
        "while delta > theta:\n",
        "    # Create a new tensor for updated values\n",
        "    # Instead of a Python loop over each state, we use tensor operations\n",
        "    # to shift the grid in each direction and handle boundaries.\n",
        "\n",
        "    # For upward movement: for row 0, stay in the same row; for others, use the row above.\n",
        "    V_up = torch.cat([V[0:1, :], V[:-1, :]], dim=0)\n",
        "\n",
        "    # For downward movement: for last row, stay in the same row; for others, use the row below.\n",
        "    V_down = torch.cat([V[1:, :], V[-1:, :]], dim=0)\n",
        "\n",
        "    # For left movement: for column 0, stay in the same column; for others, use the column to the left.\n",
        "    V_left = torch.cat([V[:, 0:1], V[:, :-1]], dim=1)\n",
        "\n",
        "    # For right movement: for last column, stay in the same column; for others, use the column to the right.\n",
        "    V_right = torch.cat([V[:, 1:], V[:, -1:]], dim=1)\n",
        "\n",
        "    # Each move yields a reward of -1 (except the terminal state which is fixed to 0).\n",
        "    Q_up    = -1 + gamma * V_up\n",
        "    Q_down  = -1 + gamma * V_down\n",
        "    Q_left  = -1 + gamma * V_left\n",
        "    Q_right = -1 + gamma * V_right\n",
        "\n",
        "    # The new value is the average over all four actions.\n",
        "    V_new = (Q_up + Q_down + Q_left + Q_right) / 4.0\n",
        "\n",
        "    # For the terminal state, enforce V(terminal) = 0.\n",
        "    V_new[terminal_mask] = 0.0\n",
        "\n",
        "    # Check convergence: maximum change in value across states.\n",
        "    delta = torch.max(torch.abs(V_new - V)).item()\n",
        "\n",
        "    # Update the value function for the next iteration.\n",
        "    V = V_new\n",
        "\n",
        "# Print the final value function (move to CPU for numpy printing if needed)\n",
        "print(\"Final Value Function:\")\n",
        "print(V.cpu().numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfewHzZeBia1",
        "outputId": "50bcc1dc-a172-49a5-9986-98755d4b8d37"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Value Function:\n",
            "[[-59.423676 -57.423866 -54.281315 -51.710125]\n",
            " [-57.423874 -54.566994 -49.710293 -45.139267]\n",
            " [-54.28131  -49.710293 -40.853916 -29.997665]\n",
            " [-51.71013  -45.139267 -29.997665   0.      ]]\n"
          ]
        }
      ]
    }
  ]
}